### Keywords

- black-box test technique
- boundary value analysis
- checklist-based testing
- coverage
- decision coverage
- decision table testing
- error guessing
- equivalence partitioning
- experience-based test technique
- exploratory testing
- state transition testing
- statement coverage
- test technique
- use case testing
- white-box test technique

### Learning Objectives for Test Techniques

#### 4.1 Categories of Test Techniques

- **FL-4.1.1 (K2)** Explain the characteristics, commonalities, and differences between black-box test techniques, white-box test techniques, and experience-based test techniques

#### 4.2 Black-box Test Techniques

- **FL-4.2.1 (K2)** Explain error guessing
- **FL-4.2.2 (K2)** Explain exploratory testing
- **FL-4.2.3 (K2)** Explain checklist-based testing
- **FL-4.2.4 (K3)** Apply equivalence partitioning to derive test cases from given requirements
- **FL-4.2.5 (K3)** Apply boundary value analysis to derive test cases from given requirements
- **FL-4.2.6 (K3)** Apply decision table testing to derive test cases from given requirements
- **FL-4.2.7 (K3)** Apply state transition testing to derive test cases from given requirements
- **FL-4.2.8 (K2)** Explain how to derive test cases from a use case

#### 4.3 White-box Test Techniques

- **FL-4.3.1 (K2)** Explain statement coverage
- **FL-4.3.2 (K2)** Explain decision coverage
- **FL-4.3.3 (K2)** Explain the value of statement and decision coverage

#### 4.4 Experience-based Test Techniques

- **FL-4.4.1 (K2)** Explain error guessing
- **FL-4.4.2 (K2)** Explain exploratory testing
- **FL-4.4.3 (K2)** Explain checklist-based testing

### 4.1 Categories of Test Techniques

The purpose of a test technique, including those discussed in this section, is to help in identifying test conditions, test cases, and test data. The choice of which test techniques to use depends on a number of factors, including:

- Component or system complexity
- Regulatory standards
- Customer or contractual requirements
- Risk levels and types
- Available documentation
- Tester knowledge and skills
- Available tools
- Time and budget
- Software development lifecycle model
- The types of defects expected in the component or system

Some techniques are more applicable to certain situations and test levels; others are applicable to all test levels. When creating test cases, testers generally use a combination of test techniques to achieve the best results from the test effort.

The use of test techniques in the test analysis, test design, and test implementation activities can range from very informal (little to no documentation) to very formal. The appropriate level of formality depends on the context of testing, including the maturity of test and development processes, time constraints, safety or regulatory requirements, the knowledge and skills of the people involved, and the software development lifecycle model being followed.

#### 4.1.1 Categories of Test Techniques and Their Characteristics

In this syllabus, test techniques are classified as black-box, white-box, or experience-based.

- **Black-box test techniques** (also called behavioral or behavior-based techniques) are based on an analysis of the appropriate test basis (e.g., formal requirements documents, specifications, use cases, user stories, or business processes). These techniques are applicable to both functional and non-functional testing. Black-box test techniques concentrate on the inputs and outputs of the test object without reference to its internal structure.

- **White-box test techniques** (also called structural or structure-based techniques) are based on an analysis of the architecture, detailed design, internal structure, or the code of the test object. Unlike black-box test techniques, white-box test techniques concentrate on the structure and processing within the test object.

- **Experience-based test techniques** leverage the experience of developers, testers, and users to design, implement, and execute tests. These techniques are often combined with black-box and white-box test techniques.

**Common characteristics of black-box test techniques include the following:**

- Test conditions, test cases, and test data are derived from a test basis that may include software requirements, specifications, use cases, and user stories.
- Test cases may be used to detect gaps between the requirements and the implementation of the requirements, as well as deviations from the requirements.
- Coverage is measured based on the items tested in the test basis and the technique applied to the test basis.

**Common characteristics of white-box test techniques include:**

- Test conditions, test cases, and test data are derived from a test basis that may include code, software architecture, detailed design, or any other source of information regarding the structure of the software.
- Coverage is measured based on the items tested within a selected structure (e.g., the code or interfaces) and the technique applied to the test basis.

**Common characteristics of experience-based test techniques include:**

- Test conditions, test cases, and test data are derived from a test basis that may include knowledge and experience of testers, developers, users, and other stakeholders.
- This knowledge and experience include expected use of the software, its environment, likely defects, and the distribution of those defects.

The international standard (ISO/IEC/IEEE 29119-4) contains descriptions of test techniques and their corresponding coverage measures (see Craig 2002 and Copeland 2004 for more on techniques).

### 4.2 Black-box Test Techniques

#### 4.2.1 Equivalence Partitioning

Equivalence partitioning divides data into partitions (also known as equivalence classes) in such a way that all the members of a given partition are expected to be processed in the same way (see Kaner 2013 and Jorgensen 2014). There are equivalence partitions for both valid and invalid values.

- Valid values are values that should be accepted by the component or system. An equivalence partition containing valid values is called a “valid equivalence partition.”
- Invalid values are values that should be rejected by the component or system. An equivalence partition containing invalid values is called an “invalid equivalence partition.”
- Partitions can be identified for any data element related to the test object, including inputs, outputs, internal values, time-related values (e.g., before or after an event) and for interface parameters (e.g., integrated components being tested during integration testing).
- Any partition may be divided into sub-partitions if required.
- Each value must belong to one and only one equivalence partition.
- When invalid equivalence partitions are used in test cases, they should be tested individually, i.e., not combined with other invalid equivalence partitions, to ensure that failures are not masked. Failures can be masked when several failures occur at the same time but only one is visible, causing the other failures to be undetected.

To achieve 100% coverage with this technique, test cases must cover all identified partitions (including invalid partitions) by using a minimum of one value from each partition. Coverage is measured as the number of equivalence partitions tested by at least one value, divided by the total number of identified equivalence partitions, normally expressed as a percentage. Equivalence partitioning is applicable at all test levels.

#### 4.2.2 Boundary Value Analysis

Boundary value analysis (BVA) is an extension of equivalence partitioning but can only be used when the partition is ordered, consisting of numeric or sequential data. The minimum and maximum values (or first and last values) of a partition are its boundary values (see Beizer 1990).

For example, suppose an input field accepts a single integer value as an input, using a keypad to limit inputs so that non-integer inputs are impossible. The valid range is from 1 to 5, inclusive. So, there are three equivalence partitions: invalid (too low); valid; invalid (too high). For the valid equivalence partition, the boundary values are 1 and 5. For the invalid (too high) partition, the boundary

- A blank means the action should not occur (may also be shown as – or N or F or 0).

A full decision table has enough columns (test cases) to cover every combination of conditions. By deleting columns that do not affect the outcome, the number of test cases can decrease considerably. For example, by removing impossible combinations of conditions. For more information on how to collapse decision tables, see ISTQB-CTAL-AT.

The common minimum coverage standard for decision table testing is to have at least one test case per decision rule in the table. This typically involves covering all combinations of conditions. Coverage is measured as the number of decision rules tested by at least one test case, divided by the total number of decision rules, normally expressed as a percentage.

The strength of decision table testing is that it helps to identify all the important combinations of conditions, some of which might otherwise be overlooked. It also helps in finding any gaps in the requirements. It may be applied to all situations in which the behavior of the software depends on a combination of conditions, at any test level.
