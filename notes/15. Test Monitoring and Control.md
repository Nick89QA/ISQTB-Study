### Test Monitoring and Control

The **purpose of test monitoring** is to gather information and provide feedback and visibility about test activities. Information to be monitored may be collected manually or automatically and should be used to assess test progress and to measure whether the test exit criteria, or the testing tasks associated with an Agile project's definition of done, are satisfied. This includes meeting the targets for coverage of product risks, requirements, or acceptance criteria.

**Test control** describes any guiding or corrective actions taken as a result of information and metrics gathered and (possibly) reported. Actions may cover any test activity and may affect any other software lifecycle activity.

### Examples of Test Control Actions
- **Re-prioritizing tests**: When a risk is identified, such as software being delivered late, test priorities may be adjusted.
- **Changing the test schedule**: This may occur due to the availability or unavailability of a test environment or other resources.
- **Re-evaluating test items**: Assessing whether a test item meets entry or exit criteria after rework.

---

### 5.3.1 Metrics Used in Testing

Metrics are collected during and at the end of test activities to assess:
- **Progress**: Against planned schedule and budget.
- **Test object quality**: Current status and quality level.
- **Test approach adequacy**: How suitable the testing approach is.
- **Test activity effectiveness**: The effectiveness in meeting test objectives.

Common test metrics include:
- Percentage of planned work done in test case preparation or implementation.
- Percentage of planned work done in test environment preparation.
- Test case execution status: Test cases run, passed, failed, or not run.
- Defect information: Defect density, found/fixed defects, failure rate, and confirmation test results.
- Test coverage: Coverage of requirements, user stories, risks, or code.
- Resource allocation, task completion, and effort.
- Testing costs: Including the cost of finding the next defect or running the next test.

---

### 5.3.2 Purposes, Contents, and Audiences for Test Reports

**Purpose**: To summarize and communicate test activity information during and at the end of testing (e.g., a test level).
- **Test progress report**: Summarizes information during a test activity.
- **Test summary report**: Summarizes information at the end of a test activity.

**Test progress report** contents:
- Status of test activities and progress against the plan.
- Factors impeding progress.
- Testing planned for the next period.
- Quality of the test object.

**Test summary report** contents:
- Summary of testing performed.
- Events during the test period.
- Deviations from the plan (schedule, effort, or duration).
- Status of testing and product quality related to exit criteria.
- Metrics for defects, test cases, test coverage, activity progress, and resource consumption.
- Residual risks.
- Reusable test work products.

Test reports should be tailored to the project and audience:
- **Technical audience**: Focus on defect details and trends.
- **Executive summary**: High-level summaries of defects, budget, schedule, and test status.

---

### 5.4 Configuration Management

**Purpose**: To maintain the integrity of components, systems, testware, and their relationships throughout the lifecycle.

To support testing, configuration management ensures:
- All test items are uniquely identified, version-controlled, tracked, and related.
- All testware is uniquely identified, version-controlled, and traceable to test items.
- Unambiguous reference to documents and software items in test documentation.

---

### 5.5 Risks and Testing

#### 5.5.1 Definition of Risk
Risk is the possibility of a future event with negative consequences, measured by its likelihood and impact.

#### 5.5.2 Product and Project Risks
**Product risks**: Risks that a work product may fail to meet user or stakeholder needs, especially regarding quality characteristics (e.g., reliability, performance).

Examples of product risks:
- Software may not perform intended functions according to specifications or user needs.
- System architecture may not support non-functional requirements.
- A computation may be incorrect in specific scenarios.
- Response times may be inadequate in high-performance systems.
- User experience feedback may fall short of expectations.

### Project Risk Examples and Their Impact

#### Project Issues:
- **Delays in delivery**: Tasks may not be completed on time, leading to missed deadlines.
- **Inaccurate estimates**: Budget overruns due to poor estimation or shifting priorities.
- **Late changes**: Substantial re-work might be needed if changes are introduced late.

#### Organizational Issues:
- **Insufficient resources**: Lack of trained staff or necessary skills may hinder progress.
- **Personnel conflicts**: Internal team issues may create project inefficiencies.
- **Availability conflicts**: Key personnel or stakeholders may be unavailable due to competing priorities.

#### Political Issues:
- **Communication gaps**: Testers or developers might fail to share results or follow-up effectively.
- **Improper attitudes**: Lack of appreciation for testing may result in undervaluing defect identification.

#### Technical Issues:
- **Poorly defined requirements**: This could lead to unmet project goals.
- **Inadequate test environment**: Delays in setting up the test environment might affect the timeline.
- **Process weaknesses**: Inconsistencies in design, code, or testing could degrade project quality.

#### Supplier Issues:
- **Third-party failure**: If a vendor cannot deliver on time or goes bankrupt, it can severely impact the project.
- **Contractual problems**: Issues with agreements can lead to delays or unexpected costs.

---

### Risk-Based Testing and Product Quality

- **Purpose of Risk-Based Testing**: Focuses testing efforts on areas of high risk, mitigating the potential for major failures.
- **Key Activities**:
    - Prioritize testing based on risk analysis.
    - Implement appropriate test levels and techniques (e.g., security testing).
    - Use testing as a mitigation strategy to lower the chance or impact of risks.

- **Benefits**:
    - Allows teams to focus on finding critical defects early.
    - Encourages proactive risk management through regular re-evaluation.
    - Helps in identifying, mitigating, and managing product risks, improving overall quality.

---

### Defect Management

- **Logging defects**: Defects found during testing are logged for tracking and resolution.
- **Defect lifecycle**: Involves discovery, classification, and resolution (e.g., fixing, deferring, or accepting as a limitation).
- **Key aspects of defect reports**:
    - Detailed defect description, logs, or screenshots.
    - Scope of impact (severity) and urgency (priority).
    - Lifecycle state (e.g., open, closed, deferred).

- **Defect management process**: Ensures effective collaboration between developers, testers, and other stakeholders for timely resolution.
